name: Jekyll site CI

on:
  push:
    branches:
      - main
      - master
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.2'
          bundler-cache: true

      - name: Setup Pages
        id: pages
        uses: actions/configure-pages@v4

      - name: Build with Jekyll
        run: bundle exec jekyll build --baseurl ""
        env:
          JEKYLL_ENV: production

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3

  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  # ë„¤ì´ë²„ IndexNow ìë™ ì œì¶œ
  submit-to-naver-indexnow:
    runs-on: ubuntu-latest
    needs: deploy
    if: github.event_name == 'push' && github.event.head_commit.message != ''
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # ì´ì „ ì»¤ë°‹ê³¼ ë¹„êµí•˜ê¸° ìœ„í•´

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Extract and submit URLs to Naver IndexNow
        run: |
          python3 << 'EOF'
          import os
          import json
          import subprocess
          import re
          import requests
          from pathlib import Path

          # ë³€ê²½ëœ í¬ìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸°
          before_sha = os.environ.get('GITHUB_BEFORE', 'HEAD~1')
          after_sha = os.environ.get('GITHUB_AFTER', 'HEAD')

          try:
              result = subprocess.run(
                  ['git', 'diff', '--name-only', before_sha, after_sha],
                  capture_output=True,
                  text=True,
                  check=True
              )
          except subprocess.CalledProcessError:
              # ì²« ì»¤ë°‹ì¸ ê²½ìš° ë¹ˆ ê²°ê³¼ ì²˜ë¦¬
              result = subprocess.run(
                  ['git', 'ls-files', '_posts/'],
                  capture_output=True,
                  text=True
              )

          changed_posts = [f for f in result.stdout.split('\n') if f.strip().startswith('_posts/') and f.strip().endswith('.md')]

          if not changed_posts:
              print("â„¹ï¸  No changed posts found")
              exit(0)

          print(f"ğŸ“ Found {len(changed_posts)} changed post(s)")

          urls = []
          for post_file in changed_posts:
              post_file = post_file.strip()
              if not post_file:
                  continue

              post_path = Path(post_file)
              if not post_path.exists():
                  print(f"âš ï¸  File not found: {post_file}")
                  continue

              try:
                  # Front matterì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                  with open(post_path, 'r', encoding='utf-8') as f:
                      content = f.read()

                  # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                  category_match = re.search(r'^categories:\s*(.+)$', content, re.MULTILINE)
                  if category_match:
                      category_raw = category_match.group(1).strip().strip('[]').strip('"').strip("'")
                      # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©
                      category = category_raw.split('/')[0].split(',')[0].strip()
                  else:
                      print(f"âš ï¸  No category found in {post_file}")
                      continue

                  # ì œëª© ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì œê±°)
                  title = post_path.stem
                  title = re.sub(r'^\d{4}-\d{2}-\d{2}-', '', title)

                  if not category or not title:
                      print(f"âš ï¸  Invalid category or title in {post_file}")
                      continue

                  url = f"https://mustarddata.com/{category}/{title}/"
                  urls.append(url)
                  print(f"âœ… Found URL: {url}")

              except Exception as e:
                  print(f"âŒ Error processing {post_file}: {e}")
                  continue

          if not urls:
              print("âš ï¸  No valid URLs found")
              exit(0)

          # ë„¤ì´ë²„ IndexNow API í˜¸ì¶œ
          key = os.environ.get('NAVER_INDEXNOW_KEY')
          if not key:
              print("âŒ NAVER_INDEXNOW_KEY secret is not set")
              print("ğŸ’¡ Please set NAVER_INDEXNOW_KEY in GitHub Secrets")
              exit(0)  # ì‹¤íŒ¨í•˜ì§€ ì•Šê³  ê²½ê³ ë§Œ ì¶œë ¥

          payload = {
              "host": "mustarddata.com",
              "key": key,
              "keyLocation": f"https://mustarddata.com/{key}.txt",
              "urlList": urls
          }

          print(f"\nğŸš€ Submitting {len(urls)} URL(s) to Naver IndexNow...")
          print(f"ğŸ“‹ URLs: {json.dumps(urls, indent=2, ensure_ascii=False)}")

          try:
              response = requests.post(
                  "https://searchadvisor.naver.com/indexnow",
                  json=payload,
                  headers={"Content-Type": "application/json; charset=utf-8"},
                  timeout=30
              )

              print(f"\nğŸ“Š Status Code: {response.status_code}")

              if response.status_code == 200:
                  print("âœ… Successfully submitted to Naver IndexNow")
              elif response.status_code == 202:
                  print("âœ… Accepted - Naver is verifying the key")
              elif response.status_code == 403:
                  print("âŒ Forbidden - Key is invalid. Please check your key file.")
              elif response.status_code == 422:
                  print("âŒ Unprocessable Entity - URL doesn't match key domain")
              elif response.status_code == 429:
                  print("âš ï¸  Too Many Requests - Please wait before next submission")
              else:
                  print(f"âš ï¸  Unexpected response: {response.text}")

          except requests.exceptions.RequestException as e:
              print(f"âŒ Request failed: {e}")
              exit(1)
          EOF
        env:
          NAVER_INDEXNOW_KEY: ${{ secrets.NAVER_INDEXNOW_KEY }}
          GITHUB_BEFORE: ${{ github.event.before }}
          GITHUB_AFTER: ${{ github.event.after }}

  # Google Search Console Indexing API ìë™ ì œì¶œ (ì„ íƒì‚¬í•­)
  # ì‚¬ìš©í•˜ë ¤ë©´ Google Cloud Consoleì—ì„œ ì„œë¹„ìŠ¤ ê³„ì •ì„ ìƒì„±í•˜ê³ 
  # Search Consoleì— ì†Œìœ ìë¡œ ì¶”ê°€í•œ í›„, JSON í‚¤ë¥¼ GitHub Secretsì— ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤.
  submit-to-google-indexing:
    runs-on: ubuntu-latest
    needs: deploy
    if: github.event_name == 'push' && github.event.head_commit.message != '' && secrets.GOOGLE_SERVICE_ACCOUNT_JSON != ''
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Google API libraries
        run: |
          pip install google-api-python-client google-auth-httplib2 google-auth

      - name: Extract and submit URLs to Google Indexing API
        run: |
          python3 << 'EOF'
          import os
          import json
          import subprocess
          import re
          from pathlib import Path
          from google.oauth2 import service_account
          from googleapiclient.discovery import build

          # ë³€ê²½ëœ í¬ìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸°
          before_sha = os.environ.get('GITHUB_BEFORE', 'HEAD~1')
          after_sha = os.environ.get('GITHUB_AFTER', 'HEAD')

          try:
              result = subprocess.run(
                  ['git', 'diff', '--name-only', before_sha, after_sha],
                  capture_output=True,
                  text=True,
                  check=True
              )
          except subprocess.CalledProcessError:
              result = subprocess.run(
                  ['git', 'ls-files', '_posts/'],
                  capture_output=True,
                  text=True
              )

          changed_posts = [f for f in result.stdout.split('\n') if f.strip().startswith('_posts/') and f.strip().endswith('.md')]

          if not changed_posts:
              print("â„¹ï¸  No changed posts found")
              exit(0)

          print(f"ğŸ“ Found {len(changed_posts)} changed post(s)")

          urls = []
          for post_file in changed_posts:
              post_file = post_file.strip()
              if not post_file:
                  continue

              post_path = Path(post_file)
              if not post_path.exists():
                  continue

              try:
                  with open(post_path, 'r', encoding='utf-8') as f:
                      content = f.read()

                  category_match = re.search(r'^categories:\s*(.+)$', content, re.MULTILINE)
                  if category_match:
                      category_raw = category_match.group(1).strip().strip('[]').strip('"').strip("'")
                      category = category_raw.split('/')[0].split(',')[0].strip()
                  else:
                      continue

                  title = post_path.stem
                  title = re.sub(r'^\d{4}-\d{2}-\d{2}-', '', title)

                  if not category or not title:
                      continue

                  url = f"https://mustarddata.com/{category}/{title}/"
                  urls.append(url)
                  print(f"âœ… Found URL: {url}")

              except Exception as e:
                  print(f"âŒ Error processing {post_file}: {e}")
                  continue

          if not urls:
              print("âš ï¸  No valid URLs found")
              exit(0)

          # Google Indexing API ì¸ì¦
          service_account_info = json.loads(os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON', '{}'))
          if not service_account_info:
              print("âš ï¸  GOOGLE_SERVICE_ACCOUNT_JSON is not set")
              exit(0)

          credentials = service_account.Credentials.from_service_account_info(
              service_account_info,
              scopes=['https://www.googleapis.com/auth/indexing']
          )

          service = build('indexing', 'v3', credentials=credentials)

          print(f"\nğŸš€ Submitting {len(urls)} URL(s) to Google Indexing API...")

          success_count = 0
          for url in urls:
              try:
                  request_body = {
                      'url': url,
                      'type': 'URL_UPDATED'
                  }

                  response = service.urlNotifications().publish(body=request_body).execute()
                  print(f"âœ… Submitted: {url}")
                  success_count += 1

              except Exception as e:
                  print(f"âŒ Failed to submit {url}: {e}")

          print(f"\nğŸ“Š Successfully submitted {success_count}/{len(urls)} URL(s)")
          EOF
        env:
          GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
          GITHUB_BEFORE: ${{ github.event.before }}
          GITHUB_AFTER: ${{ github.event.after }}

